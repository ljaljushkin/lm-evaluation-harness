{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, onnx, openvino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used along with export=True. It will be ignored.\n",
      "Compiling the model to CPU ...\n",
      "Setting OpenVINO CACHE_DIR to /home/devuser/nlyalyus/projects/lm-evaluation-harness/cache/stable-zephyr-3b-dpo/fp16/model_cache\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "import traceback\n",
    "from nncf import compress_weights\n",
    "from tqdm import trange\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import copy\n",
    "from optimum.intel.openvino import OVModelForCausalLM\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig\n",
    ")\n",
    "from nncf.parameters import CompressWeightsMode\n",
    "from whowhatbench import Evaluator\n",
    "\n",
    "from optimum.utils import NormalizedTextConfig, NormalizedConfigManager\n",
    "from optimum.exporters import TasksManager\n",
    "from openvino import Core\n",
    "core = Core()\n",
    "\n",
    "TasksManager._SUPPORTED_MODEL_TYPE[\"stablelm-epoch\"] = TasksManager._SUPPORTED_MODEL_TYPE[\"llama\"]\n",
    "NormalizedConfigManager._conf[\"stablelm-epoch\"] = NormalizedTextConfig.with_args(\n",
    "    num_layers=\"num_hidden_layers\",\n",
    "    num_attention_heads=\"num_attention_heads\",\n",
    ")\n",
    "\n",
    "ROOT_DIR = Path('/home/devuser/nlyalyus/projects/lm-evaluation-harness/cache/stable-zephyr-3b-dpo')\n",
    "gold_folder = ROOT_DIR / \"fp16\"\n",
    "gold_ir_path = gold_folder / \"openvino_model.xml\"\n",
    "config = AutoConfig.from_pretrained(gold_folder, trust_remote_code=True)\n",
    "model_gold = OVModelForCausalLM.from_pretrained(gold_folder, config=config, trust_remote_code=True, use_cache=True)\n",
    "tokenizer_gold = AutoTokenizer.from_pretrained(gold_folder)\n",
    "evaluator = Evaluator(base_model=model_gold, tokenizer=tokenizer_gold)#, gt_data='gold.csv')\n",
    "evaluator.dump_gt('gold_all.csv')\n",
    "\n",
    "# try:\n",
    "#     num_internal_ids = 5 #229 - 2\n",
    "#     list_scores_per_stage: List[List[int]] = []\n",
    "#     optimal_ids = []\n",
    "#     for stage in range(num_internal_ids):\n",
    "#         metric_per_id = []\n",
    "#         for i in trange(num_internal_ids, desc='Exhaustive search for sensitive layer'):\n",
    "#             if i in optimal_ids:\n",
    "#                 metric_per_id.append(0)\n",
    "#                 continue\n",
    "#             # gold_ov_model = core.read_model(model=gold_ir_path)\n",
    "#             force_int8_ids = optimal_ids + [i]\n",
    "#             print('evaluate config: ', force_int8_ids)\n",
    "#             compressed_model = compress_weights(gold_ov_model, mode=CompressWeightsMode.INT4_SYM, ratio=1, group_size=64, force_int8_ids=force_int8_ids)\n",
    "#             cmp_model = OVModelForCausalLM(compressed_model, config=config, trust_remote_code=True, use_cache=True, model_save_dir=gold_folder)\n",
    "#             all_metrics_per_question, all_metrics = evaluator.score(cmp_model)\n",
    "#             print(all_metrics)\n",
    "#             similarity = float(all_metrics['similarity'])\n",
    "#             sdt_norm = float(all_metrics['SDT norm'])\n",
    "#             score = (similarity + sdt_norm) / 2\n",
    "\n",
    "#             # print(all_metrics_per_question)\n",
    "#             metric_per_id.append(score)\n",
    "#         best_score = max(metric_per_id)\n",
    "#         optimal_id = metric_per_id.index(best_score)\n",
    "#         print('all scores=', metric_per_id)\n",
    "#         print('best score', best_score)\n",
    "#         print('choose layer with index=', optimal_id)\n",
    "#         optimal_ids.append(optimal_id)\n",
    "#         list_scores_per_stage.append(metric_per_id)\n",
    "# except Exception as error:\n",
    "#     print(traceback.print_exc())\n",
    "# finally:\n",
    "#     model_cache_dir = gold_folder / 'model_cache'\n",
    "#     if model_cache_dir.exists():\n",
    "#         shutil.rmtree(model_cache_dir)\n",
    "\n",
    "#     scores_path = gold_folder / 'greedy_search_result.json'\n",
    "#     results = {\n",
    "#         'scores_per_stage': list_scores_per_stage,\n",
    "#         'optimal_ids': optimal_ids,\n",
    "#     }\n",
    "#     with scores_path.open('w') as f:\n",
    "#         json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the model to CPU ...\n",
      "Setting OpenVINO CACHE_DIR to /home/devuser/nlyalyus/projects/lm-evaluation-harness/cache/stable-zephyr-3b-dpo/fp16/model_cache\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from optimum.intel.openvino import OVModelForCausalLM\n",
    "from transformers import AutoConfig\n",
    "from openvino import Core\n",
    "\n",
    "ROOT_DIR = Path('/home/devuser/nlyalyus/projects/lm-evaluation-harness/cache/stable-zephyr-3b-dpo')\n",
    "gold_path = ROOT_DIR / \"fp16\"\n",
    "ir_path =  gold_path / \"openvino_model.xml\"\n",
    "config_gold = AutoConfig.from_pretrained(gold_path, trust_remote_code=True)\n",
    "\n",
    "core = Core()\n",
    "ov_model = core.read_model(model=ir_path)\n",
    "\n",
    "from optimum.utils import NormalizedTextConfig, NormalizedConfigManager\n",
    "from optimum.exporters import TasksManager\n",
    "\n",
    "TasksManager._SUPPORTED_MODEL_TYPE[\"stablelm-epoch\"] = TasksManager._SUPPORTED_MODEL_TYPE[\"llama\"]\n",
    "NormalizedConfigManager._conf[\"stablelm-epoch\"] = NormalizedTextConfig.with_args(\n",
    "    num_layers=\"num_hidden_layers\",\n",
    "    num_attention_heads=\"num_attention_heads\",\n",
    ")\n",
    "\n",
    "model_gold = OVModelForCausalLM(ov_model, config=config_gold, trust_remote_code=True, use_cache=True, model_save_dir=gold_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold path: /dev/data/nlyalyus/cache/llama-2-7b-chat-hf/fp16/gold_all.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used along with export=True. It will be ignored.\n"
     ]
    },
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/dev/data/nlyalyus/cache/llama-2-7b-chat-hf/int4_g64_nozp_r80'. Use `repo_type` argument if needed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 66\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m exp_name \u001b[38;5;129;01min\u001b[39;00m EXP_NAMES:\n\u001b[1;32m     65\u001b[0m     cmp_ir_path \u001b[38;5;241m=\u001b[39m ROOT_DIR \u001b[38;5;241m/\u001b[39m exp_name\n\u001b[0;32m---> 66\u001b[0m     cmp_model \u001b[38;5;241m=\u001b[39m \u001b[43mOVModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmp_ir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     all_metrics_per_question, all_metrics \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mscore(cmp_model)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(all_metrics)\n",
      "File \u001b[0;32m~/nlyalyus/env/lm-eval-repro/lib/python3.8/site-packages/optimum/modeling_base.py:372\u001b[0m, in \u001b[0;36mOptimizedModel.from_pretrained\u001b[0;34m(cls, model_id, export, force_download, use_auth_token, cache_dir, subfolder, config, local_files_only, trust_remote_code, revision, **kwargs)\u001b[0m\n\u001b[1;32m    369\u001b[0m     trust_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    371\u001b[0m from_pretrained_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_transformers \u001b[38;5;28;01mif\u001b[39;00m export \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_pretrained\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_pretrained_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nlyalyus/env/lm-eval-repro/lib/python3.8/site-packages/optimum/intel/openvino/modeling_decoder.py:470\u001b[0m, in \u001b[0;36mOVModelForCausalLM._from_pretrained\u001b[0;34m(cls, model_id, config, use_auth_token, revision, force_download, cache_dir, file_name, subfolder, from_onnx, local_files_only, load_in_8bit, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m default_file_name \u001b[38;5;241m=\u001b[39m ONNX_WEIGHTS_NAME \u001b[38;5;28;01mif\u001b[39;00m from_onnx \u001b[38;5;28;01melse\u001b[39;00m OV_XML_FILE_NAME\n\u001b[1;32m    468\u001b[0m file_name \u001b[38;5;241m=\u001b[39m file_name \u001b[38;5;129;01mor\u001b[39;00m default_file_name\n\u001b[0;32m--> 470\u001b[0m model_cache_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mload_model(model_cache_path, load_in_8bit\u001b[38;5;241m=\u001b[39mload_in_8bit)\n\u001b[1;32m    483\u001b[0m model_type \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/nlyalyus/env/lm-eval-repro/lib/python3.8/site-packages/optimum/intel/openvino/modeling_base.py:236\u001b[0m, in \u001b[0;36mOVBaseModel._cached_file\u001b[0;34m(model_path, use_auth_token, revision, force_download, cache_dir, file_name, subfolder, local_files_only)\u001b[0m\n\u001b[1;32m    234\u001b[0m         model_file_names \u001b[38;5;241m=\u001b[39m [file_name]\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m model_file_names:\n\u001b[0;32m--> 236\u001b[0m         model_cache_path \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_posix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_posix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m     model_cache_path \u001b[38;5;241m=\u001b[39m Path(model_cache_path)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_cache_path\n",
      "File \u001b[0;32m~/nlyalyus/env/lm-eval-repro/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg_name, arg_value \u001b[38;5;129;01min\u001b[39;00m chain(\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mzip\u001b[39m(signature\u001b[38;5;241m.\u001b[39mparameters, args),  \u001b[38;5;66;03m# Args values\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mitems(),  \u001b[38;5;66;03m# Kwargs values\u001b[39;00m\n\u001b[1;32m    108\u001b[0m ):\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m         \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m         has_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/nlyalyus/env/lm-eval-repro/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:158\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be a string, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(repo_id)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/dev/data/nlyalyus/cache/llama-2-7b-chat-hf/int4_g64_nozp_r80'. Use `repo_type` argument if needed."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import traceback\n",
    "from nncf import compress_weights\n",
    "from tqdm import trange\n",
    "import json\n",
    "import shutil\n",
    "import random\n",
    "import copy\n",
    "from optimum.intel.openvino import OVModelForCausalLM\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig\n",
    ")\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "from nncf.parameters import CompressWeightsMode\n",
    "from whowhatbench import Evaluator\n",
    "\n",
    "from optimum.utils import NormalizedTextConfig, NormalizedConfigManager\n",
    "from optimum.exporters import TasksManager\n",
    "from openvino import Core\n",
    "core = Core()\n",
    "\n",
    "TasksManager._SUPPORTED_MODEL_TYPE[\"stablelm-epoch\"] = TasksManager._SUPPORTED_MODEL_TYPE[\"llama\"]\n",
    "NormalizedConfigManager._conf[\"stablelm-epoch\"] = NormalizedTextConfig.with_args(\n",
    "    num_layers=\"num_hidden_layers\",\n",
    "    num_attention_heads=\"num_attention_heads\",\n",
    ")\n",
    "#MODEL_NAME = 'stable-zephyr-3b-dpo'\n",
    "MODEL_NAME = 'llama-2-7b-chat-hf'\n",
    "\n",
    "cache_dir = Path(os.readlink('/home/devuser/nlyalyus/projects/lm-evaluation-harness/cache'))\n",
    "ROOT_DIR = cache_dir / MODEL_NAME\n",
    "gold_folder = ROOT_DIR / \"fp16\"\n",
    "gold_ir_path = gold_folder / \"openvino_model.xml\"\n",
    "gold_csv = gold_folder / 'gold_all.csv'\n",
    "config = AutoConfig.from_pretrained(gold_folder, trust_remote_code=True)\n",
    "tokenizer_gold = AutoTokenizer.from_pretrained(gold_folder)\n",
    "print('gold path:', gold_csv.resolve())\n",
    "if gold_csv.exists():\n",
    "    evaluator = Evaluator(tokenizer=tokenizer_gold, gt_data=gold_csv, test_data_path=gold_csv)\n",
    "else:\n",
    "    model_gold = OVModelForCausalLM.from_pretrained(gold_folder, config=config, trust_remote_code=True, use_cache=True)\n",
    "    evaluator = Evaluator(base_model=model_gold, tokenizer=tokenizer_gold)\n",
    "    evaluator.dump_gt(gold_csv)\n",
    "\n",
    "EXP_NAMES = [\n",
    "    # 'int4_g64_nozp_r80_greedy0_anti',\n",
    "    # 'int4_g64_nozp_r80_greedy0',\n",
    "    # 'int4_g64_nozp_r80_greedy1',\n",
    "    'int4_g64_nozp_r80',\n",
    "    'int4_g64_nozp_r80_hawq_in',\n",
    "    'int4_g64_nozp_r80_max_var',\n",
    "    'int4_g64_nozp_r80_mean_var',\n",
    "    'int4_g64_nozp_r80_mean_max',\n",
    "    # 'int4_g64_nozp_r80_criteria_OUT2',\n",
    "    # 'int4_g64_nozp_r80_baseline',\n",
    "    # 'int4_g64_nozp_r80_mean_var',\n",
    "    # 'int4_g64_nozp_r80_max_var',\n",
    "    # 'int4_g64_nozp_r80_mean_max',\n",
    "]\n",
    "\n",
    "for exp_name in EXP_NAMES:\n",
    "    cmp_ir_path = ROOT_DIR / exp_name\n",
    "    cmp_model = OVModelForCausalLM.from_pretrained(cmp_ir_path, config=config, trust_remote_code=True, use_cache=True)\n",
    "    all_metrics_per_question, all_metrics = evaluator.score(cmp_model)\n",
    "    print(all_metrics)\n",
    "    similarity = float(all_metrics['similarity'].iloc[0])\n",
    "    sdt_norm = float(all_metrics['SDT norm'].iloc[0])\n",
    "    score = (similarity + 1 - sdt_norm) / 2\n",
    "    # print(all_metrics_per_question)\n",
    "    print('final score=', score)\n",
    "    model_cache_dir = cmp_ir_path / 'model_cache'\n",
    "    if model_cache_dir.exists():\n",
    "        shutil.rmtree(model_cache_dir)\n",
    "    all_metrics.to_csv(cmp_ir_path / 'eval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7065786778926849,\n",
       " 0.6889446919614619,\n",
       " 0.6857339669828829,\n",
       " 0.6849753201007842,\n",
       " 0.6849614435718172,\n",
       " 0.6837329502855793,\n",
       " 0.68353123857129,\n",
       " 0.68353123857129,\n",
       " 0.6833621461545267,\n",
       " 0.6833621461545267,\n",
       " 0.6833621461545267,\n",
       " 0.6833621461545267,\n",
       " 0.6833621461545267,\n",
       " 0.6833621461545267,\n",
       " 0.6831865429878234,\n",
       " 0.6825421620298315,\n",
       " 0.6820468101127088,\n",
       " 0.6818355639134683,\n",
       " 0.6816900074481964]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '/home/devuser/nlyalyus/projects/lm-evaluation-harness/cache/stable-zephyr-3b-dpo/fp16/greedy_search_result.json'\n",
    "with open(s) as f:\n",
    "    j = json.load(f)\n",
    "similarity = j['scores_per_stage'][1]\n",
    "indexes_of_layers_in_ascending_order_of_errors = [\n",
    "    i[0] for i in sorted(enumerate(similarity), reverse=True, key=lambda x: x[1])\n",
    "]\n",
    "optimal_ids_1 = indexes_of_layers_in_ascending_order_of_errors[:19]\n",
    "[similarity[i] for i in optimal_ids_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96,\n",
       " 29,\n",
       " 30,\n",
       " 77,\n",
       " 41,\n",
       " 156,\n",
       " 88,\n",
       " 62,\n",
       " 53,\n",
       " 154,\n",
       " 84,\n",
       " 21,\n",
       " 22,\n",
       " 7,\n",
       " 19,\n",
       " 93,\n",
       " 12,\n",
       " 28,\n",
       " 138,\n",
       " 223]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_ids_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28,\n",
       " 115,\n",
       " 41,\n",
       " 84,\n",
       " 165,\n",
       " 48,\n",
       " 36,\n",
       " 135,\n",
       " 2,\n",
       " 8,\n",
       " 15,\n",
       " 51,\n",
       " 64,\n",
       " 199,\n",
       " 134,\n",
       " 29,\n",
       " 21,\n",
       " 106,\n",
       " 22]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_ids_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2, 8, 15, 36, 48, 51, 64, 106, 115, 134, 135, 165, 199}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(optimal_ids_1).difference(set(optimal_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{21, 22, 28, 29, 41, 84}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(optimal_ids_1).intersection(set(optimal_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>similarity</th>\n",
       "      <th>FDT</th>\n",
       "      <th>SDT</th>\n",
       "      <th>FDT norm</th>\n",
       "      <th>SDT norm</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.920754</td>\n",
       "      <td>27.368421</td>\n",
       "      <td>62.157895</td>\n",
       "      <td>0.21121</td>\n",
       "      <td>0.478138</td>\n",
       "      <td>int4_sym_g128_r80_mean_var</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.904372</td>\n",
       "      <td>19.947368</td>\n",
       "      <td>65.736842</td>\n",
       "      <td>0.15394</td>\n",
       "      <td>0.505944</td>\n",
       "      <td>int4_sym_g128_r80_max_var</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  similarity        FDT        SDT  FDT norm  SDT norm  \\\n",
       "0           0    0.920754  27.368421  62.157895   0.21121  0.478138   \n",
       "0           0    0.904372  19.947368  65.736842   0.15394  0.505944   \n",
       "\n",
       "                       metric  \n",
       "0  int4_sym_g128_r80_mean_var  \n",
       "0   int4_sym_g128_r80_max_var  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1= '/dev/data/nlyalyus/cache/llama-2-7b-chat-hf/int4_sym_g128_r80_mean_var/eval.csv'\n",
    "s2= '/dev/data/nlyalyus/cache/llama-2-7b-chat-hf/int4_sym_g128_r80_max_var/eval.csv'\n",
    "from pathlib import Path\n",
    "n1 = Path(s1).parent.name\n",
    "n2 = Path(s2).parent.name\n",
    "import pandas as pd\n",
    "p1=pd.read_csv(s1)\n",
    "p2=pd.read_csv(s2)\n",
    "p2['metric'] = [n1]\n",
    "p1['metric'] = [n2]\n",
    "pd.concat([p2, p1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>Weighted</th>\n",
       "      <th>similarity</th>\n",
       "      <th>FDT</th>\n",
       "      <th>SDT</th>\n",
       "      <th>SDT norm</th>\n",
       "      <th>FDT norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>int4_sym_g128_r80_max_var</td>\n",
       "      <td>0.699214</td>\n",
       "      <td>0.904372</td>\n",
       "      <td>19.947368</td>\n",
       "      <td>65.736842</td>\n",
       "      <td>0.505944</td>\n",
       "      <td>0.15394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      metric  Weighted  similarity        FDT        SDT  \\\n",
       "0  int4_sym_g128_r80_max_var  0.699214    0.904372  19.947368  65.736842   \n",
       "\n",
       "   SDT norm  FDT norm  \n",
       "0  0.505944   0.15394  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'Weighted' not in p1.columns:\n",
    "    p1['Weighted'] = (p1['similarity'] + 1 - p1['SDT norm']) / 2\n",
    "    # column_names = ['model', 'exp_name', 'Weighted', 'exp_name', 'similarity', 'FDT', 'SDT', 'SDT norm', 'FDT norm']\n",
    "    column_names = ['metric', 'Weighted', 'similarity', 'FDT', 'SDT', 'SDT norm', 'FDT norm']\n",
    "    p1[column_names]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
